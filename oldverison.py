import tensorflow as tf
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
from PIL import Image
import numpy as np
import os

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å MobileNetV2
model = tf.keras.applications.MobileNetV2(weights="imagenet")

async def classify_image(image_path):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é MobileNetV2"""
    img = Image.open(image_path).resize((224, 224))
    img_array = np.array(img)
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array[np.newaxis, ...])
    predictions = model.predict(img_array)
    return tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]

TOKEN = "7268432350:AAEFnQA34n6GRtpYM0PH0nMASyZwYbxxQkY"

# –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏
reply_keyboard = [
    [KeyboardButton("/help"), KeyboardButton("/start")]
]
markup = ReplyKeyboardMarkup(reply_keyboard, resize_keyboard=True, input_field_placeholder="–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É...")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    welcome_text = """
üì∑ *Image Classification Bot*
–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∏ —è –æ–ø—Ä–µ–¥–µ–ª—é —á—Ç–æ –Ω–∞ –Ω–µ–º!
    
–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/start - –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞
/help - –ü–æ–ª—É—á–∏—Ç—å —Å–ø—Ä–∞–≤–∫—É
"""
    await update.message.reply_text(welcome_text, parse_mode="Markdown", reply_markup=markup)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /help"""
    help_text = """
üÜò *–ü–æ–º–æ—â—å –ø–æ –±–æ—Ç—É*
    
–≠—Ç–æ—Ç –±–æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç—å MobileNetV2 –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ª—é–±–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∏ –±–æ—Ç –ø–æ–ø—ã—Ç–∞–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á—Ç–æ –Ω–∞ –Ω–µ–º.

üîπ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: —Ñ–æ—Ç–æ –∂–∏–≤–æ—Ç–Ω—ã—Ö, —Ä–∞—Å—Ç–µ–Ω–∏–π, —Ç–µ—Ö–Ω–∏–∫–∏ –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ
üîπ –¢–æ—á–Ω–æ—Å—Ç—å: ~75-90% –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–µ–¥–º–µ—Ç–∞
üîπ –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —á–µ—Ç–∫–∏–º–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ –æ–±—ä–µ–∫—Ç–æ–≤
    
–ö–æ–º–∞–Ω–¥—ã:
/start - –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
/help - –≠—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞
"""
    await update.message.reply_text(help_text, parse_mode="Markdown", reply_markup=markup)

async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
        photo_file = await update.message.photo[-1].get_file()
        image_path = "temp_image.jpg"
        await photo_file.download_to_drive(image_path)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º
        predictions = await classify_image(image_path)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = "üîç *–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞*:\n"
        response += "\n".join([f"‚ñ´Ô∏è {label} ({prob*100:.2f}%)" for _, label, prob in predictions])
        
        await update.message.reply_text(response, parse_mode="Markdown", reply_markup=markup)
        
    except Exception as e:
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}", reply_markup=markup)
    finally:
        if os.path.exists(image_path):
            os.remove(image_path)

def main():
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"""
    application = Application.builder().token(TOKEN).build()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(MessageHandler(filters.PHOTO, handle_image))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    application.run_polling()

if __name__ == "__main__":
    main()
